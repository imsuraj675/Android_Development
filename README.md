## **Advertisement Click Prediction**

### ðŸŽ¯ **Goal**
Predict the clicks on the advertisement depending on different attributes and user inputs of the dataset.

### ðŸ§µ **Dataset**
Link for the dataset used in the project: `https://www.kaggle.com/jahnveenarang/cvdcvd-vd`

### ðŸ§¾ **Description**
We start with Exploratory Data Analysis (EDA) and Data Visualization to gain insights from the dataset. Then, we apply various machine learning algorithms to predict whether a user will click on an advertisement. Finally, we compare the accuracies of these algorithms to identify the best-performing model.

### ðŸ§® **What I had done!**
- Imported essential libraries for data manipulation and machine learning.
- Conducted Exploratory Data Analysis (EDA) to comprehend the dataset.
- Visualized data to extract meaningful patterns and insights.
- Assessed feature correlations to understand interdependencies.
- Converted categorical features into numerical formats via feature mapping.
- Split the dataset into training and testing sets and applied scaling techniques.
- Implemented and trained four machine learning models: XGBoost, Random Forest, Gradient Boosting, and Multi-Layer Perceptron.
- Evaluated the models using confusion matrices and compared their accuracies to determine the best-performing model.

### ðŸš€ **Models Implemented**
Model Building: We implemented the following algorithms for their distinct advantages in handling various aspects of the dataset:

- XGBoost Classifier: Known for its high performance and efficiency in handling large datasets with complex patterns.
- Random Forest Classifier: Effective in reducing overfitting and providing reliable feature importance insights.
- Gradient Boosting: Powerful for capturing intricate data relationships and improving accuracy through boosting techniques.
- Multi-Layer Perceptron: Capable of capturing non-linear relationships due to its deep learning architecture.

### ðŸ“š **Libraries Needed**
Language Used - Python
<br>
Libraries Used - Pandas, Seaborn, Numpy, Matplotlib

### Data Visualization and Correlation

<img src="https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/gender.png">
<img src="https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/purchased.png">
<img src="https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/age-purchased.png">
<img src="https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/salary-purchased.png">
<img src="https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/purchased-gender.png">
<img src="https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/box-purchased-salary.png">
<img src="https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/box-purchased-age.png">
<img src='https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/correlation.png'>

### Accuracies
-	XGBoost Classifier - 92%
-	RandomForest - 90%
-	Gradient Boosting -	90%
-	Multi-Layer Perceptron - 87%
<img src = 'https://github.com/snega16/ML-Crate/blob/snega16/Advertisement%20Click%20Prediction/Images/accuracy.png'>


### Conclusion
Among all the models, XGBoost Classifier model gave almost 92% accuracy and it is the best fitted model.
<hr>

Code contributed by SNEGA S










